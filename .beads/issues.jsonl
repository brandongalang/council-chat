{"id":"cc-1","title":"Phase 1: Foundation","description":"Set up the foundational infrastructure for the Council Chat application.\n\n## Overview\nCreate the base Next.js project with all core infrastructure: database, authentication, and UI framework.\n\n## Tech Stack\n- Next.js 14+ (App Router)\n- Supabase (Auth \u0026 Database)\n- Drizzle ORM\n- shadcn/ui + Tailwind CSS\n\n## Success Criteria\n- Next.js app runs locally\n- Database connected via Drizzle\n- Auth flow functional (Supabase Auth)\n- BYOK (Bring Your Own Key) input implemented\n- Basic layout with navigation shell\n\n## Time Estimate\n~2 hours","status":"open","priority":0,"issue_type":"epic","created_at":"2025-11-29T16:00:45.776295-05:00","updated_at":"2025-11-29T23:11:20.041354066Z"}
{"id":"cc-10","title":"API key management with encryption","description":"Implement secure API key storage for OpenRouter.\n\n## Security Requirements\n- Encrypt API keys at rest using AES-256-GCM\n- Use environment variable for encryption key (ENCRYPTION_KEY)\n- Never log or expose decrypted keys\n\n## Implementation\n```typescript\n// src/lib/encryption.ts\nimport crypto from 'crypto';\n\nexport function encrypt(text: string, key: string): string {\n  const iv = crypto.randomBytes(16);\n  const cipher = crypto.createCipheriv('aes-256-gcm', Buffer.from(key, 'hex'), iv);\n  // ...\n}\n\nexport function decrypt(encryptedData: string, key: string): string {\n  // ...\n}\n```\n\n## UI\n- Settings page with API key input\n- Show masked key (last 4 chars only)\n- Test connection button\n- Delete key option\n\n## API Routes\n- POST /api/settings/api-key - Save encrypted key\n- GET /api/settings/api-key - Check if key exists (don't return actual key)\n- DELETE /api/settings/api-key - Remove key","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:02:29.279004-05:00","updated_at":"2025-11-29T16:02:29.279004-05:00","dependencies":[{"issue_id":"cc-10","depends_on_id":"cc-2","type":"parent-child","created_at":"2025-11-29T16:02:38.702875-05:00","created_by":"brandongalang"},{"issue_id":"cc-10","depends_on_id":"cc-9","type":"blocks","created_at":"2025-11-29T16:02:39.655828-05:00","created_by":"brandongalang"}]}
{"id":"cc-11","title":"Council CRUD UI","description":"Build the council management interface.\n\n## Features\n- List all councils (cards or table)\n- Create new council modal/page\n- Edit council (name, description, models, judge)\n- Delete council with confirmation\n- Duplicate council\n\n## Council Form Fields\n- Name (required)\n- Description (optional)\n- Models (multi-select from available models)\n- Judge Model (single select)\n- Per-model settings (temperature, max tokens)\n\n## UI Components\n- CouncilCard - Display council summary\n- CouncilForm - Create/edit form\n- ModelSelector - Multi-select for council models\n- JudgeSelector - Single select for judge\n\n## API Routes\n- GET /api/councils - List user's councils\n- POST /api/councils - Create council\n- GET /api/councils/[id] - Get council details\n- PUT /api/councils/[id] - Update council\n- DELETE /api/councils/[id] - Delete council","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:02:30.052371-05:00","updated_at":"2025-11-29T16:02:30.052371-05:00","dependencies":[{"issue_id":"cc-11","depends_on_id":"cc-2","type":"parent-child","created_at":"2025-11-29T16:02:38.710044-05:00","created_by":"brandongalang"},{"issue_id":"cc-11","depends_on_id":"cc-10","type":"blocks","created_at":"2025-11-29T16:02:39.662004-05:00","created_by":"brandongalang"}]}
{"id":"cc-12","title":"Model selector with popular models","description":"Create model selection component with curated model list.\n\n## Initial Model List (hardcoded)\n```typescript\nconst POPULAR_MODELS = [\n  { id: 'anthropic/claude-3.5-sonnet', name: 'Claude 3.5 Sonnet', provider: 'Anthropic' },\n  { id: 'anthropic/claude-3-opus', name: 'Claude 3 Opus', provider: 'Anthropic' },\n  { id: 'openai/gpt-4o', name: 'GPT-4o', provider: 'OpenAI' },\n  { id: 'openai/gpt-4-turbo', name: 'GPT-4 Turbo', provider: 'OpenAI' },\n  { id: 'google/gemini-pro-1.5', name: 'Gemini Pro 1.5', provider: 'Google' },\n  { id: 'meta-llama/llama-3.1-70b-instruct', name: 'Llama 3.1 70B', provider: 'Meta' },\n  { id: 'mistralai/mistral-large', name: 'Mistral Large', provider: 'Mistral' },\n];\n```\n\n## Component Features\n- Searchable dropdown\n- Group by provider\n- Show model capabilities (context length, etc.)\n- Custom model ID input for advanced users\n\n## Future Enhancement\n- Fetch models dynamically from OpenRouter API\n- Cache model list with periodic refresh","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-29T16:02:31.350511-05:00","updated_at":"2025-11-29T16:02:31.350511-05:00","dependencies":[{"issue_id":"cc-12","depends_on_id":"cc-2","type":"parent-child","created_at":"2025-11-29T16:02:38.71703-05:00","created_by":"brandongalang"},{"issue_id":"cc-12","depends_on_id":"cc-11","type":"blocks","created_at":"2025-11-29T16:02:39.667835-05:00","created_by":"brandongalang"}]}
{"id":"cc-13","title":"Default starter council template","description":"Create a default council for new users.\n\n## Default Council: 'Balanced Council'\n```typescript\nconst DEFAULT_COUNCIL = {\n  name: 'Balanced Council',\n  description: 'A balanced mix of leading models for general-purpose queries',\n  models: [\n    { modelId: 'anthropic/claude-3.5-sonnet', displayName: 'Claude' },\n    { modelId: 'openai/gpt-4o', displayName: 'GPT-4o' },\n    { modelId: 'google/gemini-pro-1.5', displayName: 'Gemini' },\n  ],\n  judgeModel: 'anthropic/claude-3.5-sonnet',\n};\n```\n\n## Implementation\n- Auto-create on first sign-in\n- Show as 'example' council\n- User can duplicate and modify\n- Cannot delete the default (or prompt to create new first)","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-29T16:02:32.108913-05:00","updated_at":"2025-11-29T16:02:32.108913-05:00","dependencies":[{"issue_id":"cc-13","depends_on_id":"cc-2","type":"parent-child","created_at":"2025-11-29T16:02:38.723188-05:00","created_by":"brandongalang"},{"issue_id":"cc-13","depends_on_id":"cc-12","type":"blocks","created_at":"2025-11-29T16:02:39.67385-05:00","created_by":"brandongalang"}]}
{"id":"cc-14","title":"Chat UI with AI Elements","description":"Implement the chat interface using Vercel AI Elements.\n\n## Dependencies\n```bash\nnpm install @ai-sdk/react ai @ai-elements/react\n```\n\n## Components to Use\n- Conversation, ConversationContent, ConversationScrollButton\n- Message, MessageContent, MessageResponse\n- PromptInput, PromptInputTextarea, PromptInputSubmit\n\n## Layout\n```\n┌─────────────────────────────────┐\n│ Council Selector    [Settings]  │\n├─────────────────────────────────┤\n│                                 │\n│   [Conversation Messages]       │\n│                                 │\n│   User: How do I...             │\n│   Assistant: [Response]         │\n│                                 │\n├─────────────────────────────────┤\n│ [Prompt Input]          [Send]  │\n└─────────────────────────────────┘\n```\n\n## Features\n- Auto-scroll to bottom on new messages\n- Empty state with suggestions\n- Loading/streaming indicators\n- Markdown rendering in responses","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:03:05.429233-05:00","updated_at":"2025-11-29T16:03:05.429233-05:00","dependencies":[{"issue_id":"cc-14","depends_on_id":"cc-3","type":"parent-child","created_at":"2025-11-29T16:03:13.679436-05:00","created_by":"brandongalang"},{"issue_id":"cc-14","depends_on_id":"cc-13","type":"blocks","created_at":"2025-11-29T16:03:14.880428-05:00","created_by":"brandongalang"}]}
{"id":"cc-15","title":"Single-model chat baseline","description":"Implement basic single-model chat to verify streaming works.\n\n## Purpose\nValidate the AI SDK + OpenRouter integration before adding complexity.\n\n## Implementation\n```typescript\n// src/app/api/chat/route.ts\nimport { streamText } from 'ai';\nimport { createOpenRouter } from '@openrouter/ai-sdk-provider';\n\nexport async function POST(req: Request) {\n  const { messages, model } = await req.json();\n  \n  const openrouter = createOpenRouter({\n    apiKey: await getUserApiKey(req),\n  });\n\n  const result = streamText({\n    model: openrouter(model),\n    messages,\n  });\n\n  return result.toUIMessageStreamResponse();\n}\n```\n\n## Validation Steps\n1. Send message, receive streamed response\n2. Conversation history maintained\n3. Different models work correctly\n4. Error handling for invalid API key","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:03:06.342799-05:00","updated_at":"2025-11-29T16:03:06.342799-05:00","dependencies":[{"issue_id":"cc-15","depends_on_id":"cc-3","type":"parent-child","created_at":"2025-11-29T16:03:13.686427-05:00","created_by":"brandongalang"},{"issue_id":"cc-15","depends_on_id":"cc-14","type":"blocks","created_at":"2025-11-29T16:03:14.886874-05:00","created_by":"brandongalang"}]}
{"id":"cc-16","title":"Parallel multi-model streaming","description":"Implement parallel streaming from all council models.\n\n## Architecture\nEach model streams independently. We need to:\n1. Fire all model requests in parallel\n2. Stream each response to its own accumulator\n3. Update UI as each stream progresses\n4. Wait for all to complete before triggering judge\n\n## Implementation Approach\n```typescript\n// Server: Return multiple streams merged\nconst streams = await Promise.all(\n  council.models.map(model =\u003e \n    streamText({\n      model: openrouter(model.modelId),\n      messages,\n    })\n  )\n);\n\n// Merge streams with model identifiers\n// Custom protocol to distinguish which model is streaming\n```\n\n## Client State\n```typescript\ninterface CouncilResponse {\n  modelId: string;\n  displayName: string;\n  content: string;\n  status: 'streaming' | 'complete' | 'error';\n  tokensIn?: number;\n  tokensOut?: number;\n}\n```\n\n## Considerations\n- Handle partial failures gracefully\n- Show progress for each model independently\n- Memory management for long conversations","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:03:07.268852-05:00","updated_at":"2025-11-29T16:03:07.268852-05:00","dependencies":[{"issue_id":"cc-16","depends_on_id":"cc-3","type":"parent-child","created_at":"2025-11-29T16:03:13.692998-05:00","created_by":"brandongalang"},{"issue_id":"cc-16","depends_on_id":"cc-15","type":"blocks","created_at":"2025-11-29T16:03:14.892702-05:00","created_by":"brandongalang"}]}
{"id":"cc-17","title":"Accordion response panel","description":"Build collapsible accordion UI for council responses.\n\n## Design\n```\n┌─────────────────────────────────┐\n│ ▶ Claude 3.5 Sonnet  ✓ 245 tok │\n├─────────────────────────────────┤\n│ ▼ GPT-4o             ● streaming│\n│ ┌─────────────────────────────┐ │\n│ │ The response content here   │ │\n│ │ with markdown rendering...  │ │\n│ └─────────────────────────────┘ │\n├─────────────────────────────────┤\n│ ▶ Gemini Pro         ✓ 198 tok │\n├─────────────────────────────────┤\n│ ▶ Llama 3.1          ✗ Error   │\n│   [Retry]                       │\n└─────────────────────────────────┘\n```\n\n## States\n- **Collapsed**: Model name + status icon + token count\n- **Expanded**: Full response with markdown\n- **Streaming**: Animated indicator, content updating\n- **Error**: Error message + retry button\n\n## Components\n- CouncilResponseAccordion (container)\n- CouncilResponseItem (individual model)\n- StreamingIndicator\n- RetryButton\n\n## Interactions\n- Click header to expand/collapse\n- All collapsed by default after judge synthesis\n- Auto-expand while streaming","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:03:08.261531-05:00","updated_at":"2025-11-29T16:03:08.261531-05:00","dependencies":[{"issue_id":"cc-17","depends_on_id":"cc-3","type":"parent-child","created_at":"2025-11-29T16:03:13.700976-05:00","created_by":"brandongalang"},{"issue_id":"cc-17","depends_on_id":"cc-16","type":"blocks","created_at":"2025-11-29T16:03:14.898522-05:00","created_by":"brandongalang"}]}
{"id":"cc-18","title":"Judge prompt engineering","description":"Design and implement the judge model prompt.\n\n## Prompt Structure\n```typescript\nconst JUDGE_SYSTEM_PROMPT = `You are a synthesis expert. You will receive responses from multiple AI models to the same user query. Your task is to:\n\n1. Analyze each response for its unique strengths and weaknesses\n2. Compare responses to identify what each model does better or worse than others\n3. Synthesize the best elements into a comprehensive final response\n\nFormat your response as:\n\n## Analysis\n[For each model, provide 2-3 bullet points on strengths and weaknesses]\n\n## Synthesis Approach\n[Explain which elements you're taking from which model and why]\n\n## Final Response\n[Your synthesized answer that incorporates the best of all responses]\n`;\n\nconst buildJudgeUserPrompt = (\n  userMessage: string,\n  responses: Array\u003c{ model: string; content: string }\u003e\n) =\u003e `\nUser Query: ${userMessage}\n\nModel Responses:\n${responses.map(r =\u003e `\n### ${r.model}\n${r.content}\n`).join('\\n')}\n\nPlease analyze these responses and provide your synthesis.\n`;\n```\n\n## Considerations\n- Keep prompt concise to save tokens\n- Be explicit about output format\n- Handle edge cases (all models failed, identical responses)","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:03:58.647991-05:00","updated_at":"2025-11-29T16:03:58.647991-05:00","dependencies":[{"issue_id":"cc-18","depends_on_id":"cc-4","type":"parent-child","created_at":"2025-11-29T16:04:07.471051-05:00","created_by":"brandongalang"},{"issue_id":"cc-18","depends_on_id":"cc-17","type":"blocks","created_at":"2025-11-29T16:04:08.293445-05:00","created_by":"brandongalang"}]}
{"id":"cc-19","title":"Streaming synthesis with collapsible reasoning","description":"Implement streaming judge response with collapsible analysis section.\n\n## Output Parsing\nParse the judge's streaming output to separate:\n1. Analysis section (## Analysis)\n2. Synthesis Approach (## Synthesis Approach)  \n3. Final Response (## Final Response)\n\n## UI Behavior\n```\n┌─────────────────────────────────┐\n│ ▶ Analysis (click to expand)   │\n├─────────────────────────────────┤\n│                                 │\n│ [Final Response streams here]  │\n│                                 │\n└─────────────────────────────────┘\n```\n\n## Implementation\n```typescript\n// Parse streaming chunks to detect sections\nconst parseJudgeStream = (chunk: string, state: ParserState) =\u003e {\n  if (chunk.includes('## Analysis')) {\n    state.section = 'analysis';\n  } else if (chunk.includes('## Final Response')) {\n    state.section = 'final';\n  }\n  // Route chunk to appropriate section\n};\n```\n\n## Components\n- JudgeSynthesis (container)\n- CollapsibleAnalysis\n- FinalResponseStream","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:04:00.145517-05:00","updated_at":"2025-11-29T16:04:00.145517-05:00","dependencies":[{"issue_id":"cc-19","depends_on_id":"cc-4","type":"parent-child","created_at":"2025-11-29T16:04:07.477968-05:00","created_by":"brandongalang"},{"issue_id":"cc-19","depends_on_id":"cc-18","type":"blocks","created_at":"2025-11-29T16:04:08.299421-05:00","created_by":"brandongalang"}]}
{"id":"cc-2","title":"Phase 2: Council Management","description":"Build the council configuration and management system.\n\n## Overview\nEnable users to create, save, edit, and delete council presets. Each council contains multiple LLM models and a designated judge model.\n\n## Data Model\n```typescript\ninterface Council {\n  id: string;\n  name: string;\n  description?: string;\n  models: CouncilModel[];      // Array of OpenRouter model IDs\n  judgeModel: string;          // OpenRouter model ID for synthesis\n  createdAt: Date;\n  updatedAt: Date;\n}\n\ninterface CouncilModel {\n  modelId: string;             // e.g., 'anthropic/claude-3.5-sonnet'\n  displayName?: string;        // Optional custom label\n  temperature?: number;        // Model-specific settings\n  maxTokens?: number;\n}\n```\n\n## Features\n- Encrypted API key storage\n- Council CRUD UI\n- Model selector with popular models\n- Default starter council template\n\n## Time Estimate\n~3 hours","status":"open","priority":0,"issue_type":"epic","created_at":"2025-11-29T16:01:08.965997-05:00","updated_at":"2025-11-29T16:01:08.965997-05:00","dependencies":[{"issue_id":"cc-2","depends_on_id":"cc-1","type":"blocks","created_at":"2025-11-29T16:02:39.649662-05:00","created_by":"brandongalang"}]}
{"id":"cc-20","title":"Response composition layout","description":"Compose the full response UI: accordion + analysis + final response.\n\n## Message Structure\n```\n┌─────────────────────────────────┐\n│ User Message                    │\n└─────────────────────────────────┘\n┌─────────────────────────────────┐\n│ Council Responses (Accordion)   │\n│ ▶ Claude: ✓ 245 tokens         │\n│ ▶ GPT-4o: ✓ 312 tokens         │\n│ ▶ Gemini: ✓ 198 tokens         │\n├─────────────────────────────────┤\n│ ▶ Analysis (collapsed)          │\n├─────────────────────────────────┤\n│ Final Synthesized Response      │\n│ [Main response content here]    │\n└─────────────────────────────────┘\n```\n\n## Interaction Flow\n1. User sends message\n2. Council responses stream (accordion auto-expands active)\n3. All complete → accordion collapses\n4. Judge streams → analysis collapsible, final response visible\n5. Complete state: accordion collapsed, analysis collapsed, final visible\n\n## Animation\n- Smooth expand/collapse transitions\n- Streaming text animation\n- Status icon transitions","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:04:01.037017-05:00","updated_at":"2025-11-29T16:04:01.037017-05:00","dependencies":[{"issue_id":"cc-20","depends_on_id":"cc-4","type":"parent-child","created_at":"2025-11-29T16:04:07.483759-05:00","created_by":"brandongalang"},{"issue_id":"cc-20","depends_on_id":"cc-19","type":"blocks","created_at":"2025-11-29T16:04:08.305448-05:00","created_by":"brandongalang"}]}
{"id":"cc-21","title":"Error handling and retry logic","description":"Implement robust error handling for model failures.\n\n## Error Types\n1. **API Key Invalid** - Prompt user to check settings\n2. **Model Unavailable** - Skip model, note in UI\n3. **Rate Limited** - Auto-retry with backoff\n4. **Timeout** - Show timeout, offer retry\n5. **Network Error** - Show error, offer retry\n\n## Retry Configuration\n```typescript\nconst RETRY_CONFIG = {\n  maxRetries: 3,\n  initialDelayMs: 1000,\n  maxDelayMs: 10000,\n  backoffMultiplier: 2,\n};\n```\n\n## Partial Success Handling\n- If some models succeed, judge synthesizes from available\n- Show which models failed in UI\n- Allow manual retry of failed models\n\n## Judge Fallback\n- If judge model fails, show raw responses without synthesis\n- Option to retry with different judge model\n\n## UI Feedback\n- Clear error messages\n- Retry buttons per model\n- 'Retry All Failed' button\n- Progress indicator during retry","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:04:01.843419-05:00","updated_at":"2025-11-29T16:04:01.843419-05:00","dependencies":[{"issue_id":"cc-21","depends_on_id":"cc-4","type":"parent-child","created_at":"2025-11-29T16:04:07.490085-05:00","created_by":"brandongalang"},{"issue_id":"cc-21","depends_on_id":"cc-20","type":"blocks","created_at":"2025-11-29T16:04:08.311245-05:00","created_by":"brandongalang"}]}
{"id":"cc-22","title":"Token counting per response","description":"Implement token counting for all LLM calls.\n\n## Data Sources\nOpenRouter returns usage in response headers/body:\n```typescript\ninterface OpenRouterUsage {\n  prompt_tokens: number;\n  completion_tokens: number;\n  total_tokens: number;\n}\n```\n\n## Storage\nStore in council_responses table:\n- tokens_in (prompt tokens)\n- tokens_out (completion tokens)\n- Update after each model completes\n\n## Display\n- Show token count in accordion header after completion\n- Format: '245 tok' or '1.2k tok' for large numbers\n- Tooltip with breakdown (in/out)\n\n## Aggregation\n- Sum tokens per message (all council + judge)\n- Sum tokens per conversation\n- Track per-model statistics","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-29T16:04:31.91725-05:00","updated_at":"2025-11-29T16:04:31.91725-05:00","dependencies":[{"issue_id":"cc-22","depends_on_id":"cc-5","type":"parent-child","created_at":"2025-11-29T16:04:41.028706-05:00","created_by":"brandongalang"},{"issue_id":"cc-22","depends_on_id":"cc-21","type":"blocks","created_at":"2025-11-29T16:04:42.328701-05:00","created_by":"brandongalang"}]}
{"id":"cc-23","title":"Cost calculation with OpenRouter pricing","description":"Calculate and display estimated costs.\n\n## Pricing Data\nFetch from OpenRouter or maintain local mapping:\n```typescript\nconst MODEL_PRICING: Record\u003cstring, { input: number; output: number }\u003e = {\n  'anthropic/claude-3.5-sonnet': { input: 3.00, output: 15.00 }, // per 1M tokens\n  'openai/gpt-4o': { input: 5.00, output: 15.00 },\n  'google/gemini-pro-1.5': { input: 3.50, output: 10.50 },\n  // ...\n};\n\nconst calculateCost = (modelId: string, tokensIn: number, tokensOut: number) =\u003e {\n  const pricing = MODEL_PRICING[modelId];\n  return (tokensIn * pricing.input + tokensOut * pricing.output) / 1_000_000;\n};\n```\n\n## Display Format\n- Per response: '$0.0023'\n- Per conversation: '$0.15'\n- Dashboard: '$4.52 this month'\n\n## Storage\n- Store calculated cost in council_responses.cost\n- Recalculate if pricing changes? Or lock at time of generation","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-29T16:04:32.718568-05:00","updated_at":"2025-11-29T16:04:32.718568-05:00","dependencies":[{"issue_id":"cc-23","depends_on_id":"cc-5","type":"parent-child","created_at":"2025-11-29T16:04:41.035827-05:00","created_by":"brandongalang"},{"issue_id":"cc-23","depends_on_id":"cc-22","type":"blocks","created_at":"2025-11-29T16:04:42.335415-05:00","created_by":"brandongalang"}]}
{"id":"cc-24","title":"Per-conversation usage display","description":"Show usage statistics within conversations.\n\n## Conversation Header Stats\n```\nCouncil Chat | Balanced Council | 12 messages | 15.2k tokens | $0.34\n```\n\n## Per-Message Breakdown (expandable)\n```\nMessage 3:\n├─ Claude: 245 in / 512 out = $0.0089\n├─ GPT-4o: 245 in / 489 out = $0.0086\n├─ Gemini: 245 in / 398 out = $0.0053\n└─ Judge:  1489 in / 623 out = $0.0156\n   Total: $0.0384\n```\n\n## UI Components\n- ConversationStats (header bar)\n- MessageCostBreakdown (expandable per message)\n- Quick cost indicator in message bubble","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-29T16:04:34.218745-05:00","updated_at":"2025-11-29T16:04:34.218745-05:00","dependencies":[{"issue_id":"cc-24","depends_on_id":"cc-5","type":"parent-child","created_at":"2025-11-29T16:04:41.042282-05:00","created_by":"brandongalang"},{"issue_id":"cc-24","depends_on_id":"cc-23","type":"blocks","created_at":"2025-11-29T16:04:42.342148-05:00","created_by":"brandongalang"}]}
{"id":"cc-25","title":"Simple usage dashboard","description":"Create a usage analytics dashboard.\n\n## Dashboard Sections\n\n### Summary Cards\n- Total tokens (this month)\n- Total cost (this month)\n- Conversations count\n- Average cost per conversation\n\n### Usage Over Time\n- Line chart: daily token usage\n- Bar chart: cost by model\n\n### Model Breakdown\n```\nModel               | Calls | Tokens  | Cost\n--------------------|-------|---------|-------\nClaude 3.5 Sonnet   | 156   | 89.2k   | $2.14\nGPT-4o              | 142   | 76.1k   | $1.89\nGemini Pro          | 138   | 52.3k   | $0.92\n```\n\n### Recent Activity\n- Last 10 conversations with cost\n\n## API Route\nGET /api/usage?period=month|week|day\n\n## Tech\n- Use Recharts or similar for charts\n- Server-side aggregation queries\n- Cache expensive queries","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-29T16:04:35.110077-05:00","updated_at":"2025-11-29T16:04:35.110077-05:00","dependencies":[{"issue_id":"cc-25","depends_on_id":"cc-5","type":"parent-child","created_at":"2025-11-29T16:04:41.048792-05:00","created_by":"brandongalang"},{"issue_id":"cc-25","depends_on_id":"cc-24","type":"blocks","created_at":"2025-11-29T16:04:42.348678-05:00","created_by":"brandongalang"}]}
{"id":"cc-3","title":"Phase 3: Core Chat Flow","description":"Implement the main chat interface with parallel multi-model streaming.\n\n## Overview\nBuild the ChatGPT-style interface where messages are sent to all council models in parallel, with responses displayed in an accordion UI.\n\n## Architecture\n- Use Vercel AI SDK with @openrouter/ai-sdk-provider\n- Parallel streaming via Promise.all with individual ReadableStreams\n- AI Elements components (Conversation, Message)\n\n## Message Flow\n1. User sends message\n2. All council models receive message in parallel\n3. Each model streams response into accordion panel\n4. Responses stored for judge synthesis\n\n## Conversation Memory\n- Council models see: user messages + synthesized judge responses\n- Council models DO NOT see: other council members' raw responses\n\n## UI Components\n- Accordion with collapsible per-model responses\n- Status indicators (streaming/complete/error)\n- Token count display after completion\n- Error state with retry button\n\n## Time Estimate\n~4 hours","status":"open","priority":0,"issue_type":"epic","created_at":"2025-11-29T16:01:10.147901-05:00","updated_at":"2025-11-29T16:01:10.147901-05:00","dependencies":[{"issue_id":"cc-3","depends_on_id":"cc-2","type":"blocks","created_at":"2025-11-29T16:03:14.873457-05:00","created_by":"brandongalang"}]}
{"id":"cc-4","title":"Phase 4: Judge Synthesis","description":"Implement the judge model synthesis with visible reasoning.\n\n## Overview\nAfter all council models respond, the judge model receives all responses and synthesizes a final answer with explicit analysis of each model's strengths and weaknesses.\n\n## Judge Prompt Structure\nThe judge receives:\n1. Original user message\n2. All council responses (labeled by model)\n3. Instructions to analyze and synthesize\n\n## Expected Output Format\n```\n## Analysis\n\n**Model A (claude-3.5-sonnet)**\n- Strengths: [specific observations]\n- Weaknesses: [specific observations]\n\n**Model B (gpt-4o)**\n- Strengths: [specific observations]\n- Weaknesses: [specific observations]\n\n## Synthesis Approach\nI will incorporate [X] from Model A because... and [Y] from Model B because...\n\n## Final Response\n[Synthesized answer]\n```\n\n## UI Requirements\n- Analysis section is COLLAPSIBLE (collapsed by default)\n- Final response is always visible\n- Streaming with progressive reveal\n\n## Error Handling\n- Timeout: configurable per-model (default 30s)\n- Auto-retry failed models up to 3 times\n- Judge synthesizes from successful responses if some fail\n\n## Time Estimate\n~3 hours","status":"open","priority":0,"issue_type":"epic","created_at":"2025-11-29T16:01:10.99303-05:00","updated_at":"2025-11-29T16:01:10.99303-05:00","dependencies":[{"issue_id":"cc-4","depends_on_id":"cc-3","type":"blocks","created_at":"2025-11-29T16:04:08.285981-05:00","created_by":"brandongalang"}]}
{"id":"cc-4jc","title":"Supabase Auth Integration","description":"Implement Supabase Authentication.\n\n## Requirements\n- Create Auth UI components (Login/Sign Up) using shadcn/ui\n- Implement Auth Provider or Context if needed (or use Supabase Auth Helpers directly)\n- Create a middleware to refresh sessions ()\n- Add Login/Logout buttons to the UI","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-29T23:10:33.591698363Z","updated_at":"2025-11-29T23:33:18.677299657Z","closed_at":"2025-11-29T23:33:18.677299657Z","dependencies":[{"issue_id":"cc-4jc","depends_on_id":"cc-1","type":"discovered-from","created_at":"2025-11-29T23:10:33.597174782Z","created_by":"jules"}]}
{"id":"cc-5","title":"Phase 5: Analytics","description":"Implement token and cost tracking across the application.\n\n## Overview\nTrack and display token usage and estimated costs for all LLM calls.\n\n## Metrics Per Response\n- Input tokens\n- Output tokens\n- Estimated cost (using OpenRouter pricing)\n- Response duration\n\n## Aggregate Stats\n- Total tokens/cost per conversation\n- Usage dashboard with historical data\n- Per-model breakdown\n\n## Database Schema\n```sql\ncouncil_responses (\n  id, message_id, model_id, content,\n  tokens_in, tokens_out, cost, duration_ms, status\n)\n```\n\n## Time Estimate\n~2 hours","status":"open","priority":1,"issue_type":"epic","created_at":"2025-11-29T16:01:12.348099-05:00","updated_at":"2025-11-29T16:01:12.348099-05:00","dependencies":[{"issue_id":"cc-5","depends_on_id":"cc-4","type":"blocks","created_at":"2025-11-29T16:04:42.321298-05:00","created_by":"brandongalang"}]}
{"id":"cc-6","title":"Next.js project setup with App Router","description":"Initialize the Next.js 14+ project with App Router.\n\n## Commands\n```bash\nnpx create-next-app@latest . --typescript --tailwind --eslint --app --src-dir --import-alias '@/*'\n```\n\n## Configuration\n- TypeScript strict mode\n- Tailwind CSS\n- ESLint\n- App Router (not Pages)\n- src/ directory structure\n- shadcn/ui initialization\n\n## Expected Structure\n```\ncouncil-chat/\n├── src/\n│   ├── app/\n│   │   ├── layout.tsx\n│   │   ├── page.tsx\n│   │   └── globals.css\n│   └── components/\n├── public/\n├── package.json\n├── tsconfig.json\n└── tailwind.config.ts\n```","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-29T16:01:46.995608-05:00","updated_at":"2025-11-29T23:21:44.923305753Z","closed_at":"2025-11-29T23:21:44.923305753Z","dependencies":[{"issue_id":"cc-6","depends_on_id":"cc-1","type":"parent-child","created_at":"2025-11-29T16:02:04.743669-05:00","created_by":"brandongalang"}]}
{"id":"cc-7","title":"Database schema + Drizzle setup","description":"Set up PostgreSQL with Drizzle ORM.\n\n## Dependencies\n- drizzle-orm\n- drizzle-kit\n- @neondatabase/serverless (or postgres for local)\n- dotenv\n\n## Schema Tables\n```sql\n-- Users (managed by NextAuth)\nusers (id, email, name, image, created_at)\n\n-- API Keys (encrypted)\napi_keys (id, user_id, provider, encrypted_key, created_at)\n\n-- Councils\ncouncils (id, user_id, name, description, judge_model, created_at, updated_at)\n\n-- Council Models (junction table)\ncouncil_models (id, council_id, model_id, display_name, temperature, max_tokens, order)\n\n-- Conversations\nconversations (id, user_id, council_id, title, created_at, updated_at)\n\n-- Messages\nmessages (id, conversation_id, role, content, created_at)\n\n-- Council Responses\ncouncil_responses (id, message_id, model_id, content, tokens_in, tokens_out, cost, duration_ms, status)\n```\n\n## Files to Create\n- src/db/schema.ts\n- src/db/index.ts\n- drizzle.config.ts\n- .env.local (with DATABASE_URL)","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:01:47.754727-05:00","updated_at":"2025-11-29T16:01:47.754727-05:00","dependencies":[{"issue_id":"cc-7","depends_on_id":"cc-1","type":"parent-child","created_at":"2025-11-29T16:02:04.750917-05:00","created_by":"brandongalang"},{"issue_id":"cc-7","depends_on_id":"cc-6","type":"blocks","created_at":"2025-11-29T16:02:05.787523-05:00","created_by":"brandongalang"}]}
{"id":"cc-8","title":"NextAuth integration with Google OAuth","description":"Set up NextAuth.js v5 with Google OAuth provider.\n\n## Dependencies\n- next-auth@beta (v5)\n- @auth/drizzle-adapter\n\n## Configuration\n1. Create Google OAuth credentials in Google Cloud Console\n2. Set up environment variables:\n   - GOOGLE_CLIENT_ID\n   - GOOGLE_CLIENT_SECRET\n   - NEXTAUTH_SECRET\n   - NEXTAUTH_URL\n\n## Files to Create\n- src/lib/auth.ts (auth configuration)\n- src/app/api/auth/[...nextauth]/route.ts\n- src/middleware.ts (protect routes)\n\n## Features\n- Sign in with Google\n- Session management\n- Protected routes\n- User stored in database via Drizzle adapter","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:01:48.645659-05:00","updated_at":"2025-11-29T16:01:48.645659-05:00","dependencies":[{"issue_id":"cc-8","depends_on_id":"cc-1","type":"parent-child","created_at":"2025-11-29T16:02:04.757774-05:00","created_by":"brandongalang"},{"issue_id":"cc-8","depends_on_id":"cc-7","type":"blocks","created_at":"2025-11-29T16:02:05.800459-05:00","created_by":"brandongalang"}]}
{"id":"cc-9","title":"Basic UI shell with shadcn/ui","description":"Set up shadcn/ui and create the basic application layout.\n\n## Setup\n```bash\nnpx shadcn-ui@latest init\nnpx shadcn-ui@latest add button card dialog dropdown-menu input label separator sheet sidebar\n```\n\n## Layout Components\n- AppShell with sidebar navigation\n- Header with user menu (sign in/out)\n- Main content area\n- Settings page placeholder\n\n## Navigation Structure\n- /chat - Main chat interface\n- /councils - Council management\n- /settings - User settings (API keys)\n- /usage - Analytics dashboard\n\n## Responsive Design\n- Collapsible sidebar on mobile\n- Full sidebar on desktop","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-29T16:01:49.709912-05:00","updated_at":"2025-11-29T16:01:49.709912-05:00","dependencies":[{"issue_id":"cc-9","depends_on_id":"cc-1","type":"parent-child","created_at":"2025-11-29T16:02:04.764453-05:00","created_by":"brandongalang"},{"issue_id":"cc-9","depends_on_id":"cc-8","type":"blocks","created_at":"2025-11-29T16:02:05.807082-05:00","created_by":"brandongalang"}]}
{"id":"cc-9nh","title":"Supabase and Drizzle Infrastructure Setup","description":"Set up Supabase client and Drizzle ORM.\n\n## Requirements\n- Install `@supabase/supabase-js`, `@supabase/ssr`, `drizzle-orm`, `drizzle-kit`, `postgres`\n- Create `src/lib/supabase/client.ts` (Client Component client)\n- Create `src/lib/supabase/server.ts` (Server Component client)\n- Configure `drizzle.config.ts`\n- Create `src/db/index.ts` (DB connection)\n- Create `src/db/schema.ts` (Basic schema with Profiles table)\n- Add env var examples to `.env.example`","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-29T23:10:14.1104477Z","updated_at":"2025-11-29T23:28:10.587707244Z","closed_at":"2025-11-29T23:28:10.587707244Z","dependencies":[{"issue_id":"cc-9nh","depends_on_id":"cc-1","type":"discovered-from","created_at":"2025-11-29T23:10:14.115617604Z","created_by":"jules"}]}
{"id":"cc-qst","title":"BYOK UI and Local Storage","description":"Implement BYOK (Bring Your Own Key) functionality.\n\n## Requirements\n- Create a UI component to input API Key\n- Implement logic to save/load key from LocalStorage\n- Ensure key is never sent to backend (except maybe when proxied, but for now just storage)\n- Display current key status (configured/missing)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-29T23:13:05.317328058Z","updated_at":"2025-11-29T23:35:39.136179363Z","closed_at":"2025-11-29T23:35:39.136179363Z","dependencies":[{"issue_id":"cc-qst","depends_on_id":"cc-1","type":"discovered-from","created_at":"2025-11-29T23:13:05.322993739Z","created_by":"jules"}]}
